{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count of Treasure Island\n",
    "    In this project we will use the spacy and nltk libraries to do a word count of \n",
    "    Robert Louis Stevenson's \"Treasure Island\". Prior to starting this analysis the \n",
    "    libraries and english core word library from spacy are installed. The second set of imports allows a connection to R in order to download the book from the r-package \n",
    "    'gutenberg'\n",
    "    \n",
    "    The code, along with the files necessary and versions of packages in this instance \n",
    "    can be found on this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpy2.robjects.packages.Package as a <module 'gutenbergr'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "utils = importr('utils')\n",
    "utils.install_packages('gutenbergr', repos='https://cloud.r-project.org')\n",
    "importr('gutenbergr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Text Cleaning Function\n",
    "    The following function will take the text given, and lemmatize all non-pronoun \n",
    "    words, while changing all pronouns to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    nlp_text = nlp(text)\n",
    "    lemmas = [w.lower_ if w.lemma == '-PRON-' else w.lemma_ \n",
    "              for w in nlp_text if w.is_alpha and not w.is_stop]\n",
    "\n",
    "    #for w in nlp_text:\n",
    "    #    if w.is_alpha and not w.is_stop:\n",
    "    #        if w.lemma == '-PRON-':\n",
    "    #            lemmas.append(w.lower_)\n",
    "    #        else:\n",
    "    #            lemmas.append(w.lemma_)\n",
    "    return(' '.join(lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Read in file and apply the function\n",
    "    This next step will read in the file chosen, strip the line breaks from each row of the list, remove the null list items, convert the list into a single string, \n",
    "    and finally apply our cleaned_text function to the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treasure_island_df = ro.r('gutenberg_download(\"120\")')\n",
    "treasure_island_full = ' '.join(treasure_island_df[1])\n",
    "treasure_island = treasure_island_full[3488:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_treasure_island = clean_text(treasure_island)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Alternatively, the file can be downloaded from \n",
    "    http://www.gutenberg.org/files/120/120-0.txt, read in and opened/cleaned with \n",
    "    the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Treasure_Island.txt', 'r', encoding = 'utf-8') as text:\n",
    "    ti_example = [line.rstrip() for line in text]\n",
    "    while('' in ti_example):\n",
    "            ti_example.remove('')\n",
    "            \n",
    "single_text_ti = ' '.join(ti_example)\n",
    "cleaned_ti = clean_text(single_text_ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Apply word count\n",
    "    Lastly, we apply the nltk package to count the frequency of words appearing in the \n",
    "    documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "treasure_island_top_words = nltk.FreqDist(cleaned_treasure_island.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 409),\n",
       " ('man', 364),\n",
       " ('come', 215),\n",
       " ('like', 214),\n",
       " ('hand', 198),\n",
       " ('captain', 188),\n",
       " ('doctor', 159),\n",
       " ('go', 152),\n",
       " ('good', 150),\n",
       " ('silver', 142),\n",
       " ('time', 139),\n",
       " ('know', 139),\n",
       " ('cry', 137),\n",
       " ('look', 133),\n",
       " ('ship', 133),\n",
       " ('think', 128),\n",
       " ('see', 126),\n",
       " ('tell', 115),\n",
       " ('old', 114),\n",
       " ('begin', 113),\n",
       " ('sea', 107),\n",
       " ('run', 104),\n",
       " ('little', 102),\n",
       " ('find', 102),\n",
       " ('hear', 101)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treasure_island_top_words.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "    From above it can be seen by simply counting single words we can't truly get a good \n",
    "    understanding for what the text contains. some of the top words with meaning \n",
    "    ('captain', 'ssilver', 'ship', 'sea') do imply the book is truly about treasure/ and island... \n",
    "    But we don't have a great understanding of the significance unless we provide \n",
    "    additional analysis\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
